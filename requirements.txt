# File: requirements.txt
# List of Python dependencies for the project.
# Install these using: pip install -r requirements.txt

opencv-python
face_recognition
numpy
Flask
imutils
```

```python
# File: src/config.py
# Configuration settings for the face recognition system.

import os

# Base directory of the project
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# Path to the directory containing known faces
KNOWN_FACES_DIR = os.path.join(BASE_DIR, "data", "known_faces")

# Path to the file where face encodings will be stored
ENCODINGS_PATH = os.path.join(BASE_DIR, "data", "encodings.pickle")

# Face detection model to use: "hog" (faster, less accurate) or "cnn" (slower, more accurate)
DETECTION_MODEL = "hog"

# Tolerance for face comparison. Lower is more strict. 0.6 is a common default.
# You might need to adjust this based on your dataset and desired accuracy.
FACE_TOLERANCE = 0.6

# --- Webcam Settings ---
# Frame width for webcam processing (smaller can be faster)
FRAME_WIDTH = 640 # pixels

# --- Display Settings ---
BOX_COLOR_KNOWN = (0, 255, 0)  # Green for known faces
BOX_COLOR_UNKNOWN = (0, 0, 255) # Red for unknown faces
TEXT_COLOR = (255, 255, 255) # White for text
```

```python
# File: src/face_utils.py
# Utility functions for the face recognition system.

import cv2
from src import config # Import from the config.py file within the same package

def draw_bounding_box_and_name(frame, name, box, is_known):
    """
    Draws a bounding box around the detected face and displays the name.

    Args:
        frame: The video frame (NumPy array) to draw on.
        name (str): The name of the recognized person or "Unknown".
        box (tuple): A tuple (top, right, bottom, left) defining the face location.
        is_known (bool): True if the face is known, False otherwise.
    """
    (top, right, bottom, left) = box
    
    # Determine color based on whether the person is known
    box_color = config.BOX_COLOR_KNOWN if is_known else config.BOX_COLOR_UNKNOWN

    # Draw a box around the face
    cv2.rectangle(frame, (left, top), (right, bottom), box_color, 2)

    # Draw a label with a name below the face
    # Adjust text position if it's too close to the top
    y_text = top - 15 if top - 15 > 15 else top + 25 # Position text above or below if too close to edge
    
    # Background for the text for better visibility
    # Get text size to draw a filled rectangle as background
    (text_width, text_height), baseline = cv2.getTextSize(name, cv2.FONT_HERSHEY_SIMPLEX, 0.65, 1)
    cv2.rectangle(frame, (left, y_text - text_height - baseline), (left + text_width, y_text + baseline), box_color, cv2.FILLED)
    
    cv2.putText(frame, name, (left, y_text), cv2.FONT_HERSHEY_SIMPLEX, 0.65, config.TEXT_COLOR, 1)
```

```python
# File: src/face_encoder.py
# Module to handle encoding of faces from images in the known_faces directory.

import face_recognition
import pickle
import cv2
import os
from imutils import paths
from src import config # Import from the config.py file

def build_known_faces_encodings():
    """
    Processes images in the KNOWN_FACES_DIR, computes face encodings,
    and saves them to ENCODINGS_PATH.
    """
    print("[INFO] Quantifying faces...")
    image_paths = list(paths.list_images(config.KNOWN_FACES_DIR))

    known_encodings = []
    known_names = []

    if not image_paths:
        print(f"[WARNING] No images found in {config.KNOWN_FACES_DIR}. Encodings file will be empty or not created.")
        # Create an empty encodings file or handle as preferred
        data = {"encodings": [], "names": []}
        with open(config.ENCODINGS_PATH, "wb") as f:
            f.write(pickle.dumps(data))
        print(f"[INFO] Empty encodings file created at {config.ENCODINGS_PATH}")
        return

    # Loop over the image paths
    for (i, image_path) in enumerate(image_paths):
        # Extract the person name from the image path (assumes directory structure: known_faces/person_name/image.jpg)
        print(f"[INFO] Processing image {i + 1}/{len(image_paths)}: {image_path}")
        name = image_path.split(os.path.sep)[-2] # The name is the directory name

        # Load the input image and convert it from BGR (OpenCV ordering) to RGB (dlib ordering)
        try:
            image = cv2.imread(image_path)
            if image is None:
                print(f"[WARNING] Could not read image {image_path}. Skipping.")
                continue
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        except Exception as e:
            print(f"[ERROR] Could not process image {image_path}: {e}. Skipping.")
            continue

        # Detect the (x, y)-coordinates of the bounding boxes corresponding to each face in the input image
        # The "detection_model" can be "hog" or "cnn"
        boxes = face_recognition.face_locations(rgb_image, model=config.DETECTION_MODEL)

        # Compute the facial embedding for the face
        encodings = face_recognition.face_encodings(rgb_image, boxes)

        # Loop over the encodings (usually one per image if images contain one clear face)
        for encoding in encodings:
            # Add each encoding + name to our set of known names and encodings
            known_encodings.append(encoding)
            known_names.append(name)
        
        if not encodings and boxes:
             print(f"[WARNING] Face detected in {image_path} but no encoding could be computed.")
        elif not boxes:
             print(f"[WARNING] No faces detected in {image_path}.")


    # Dump the facial encodings + names to disk
    print("[INFO] Serializing encodings...")
    data = {"encodings": known_encodings, "names": known_names}
    with open(config.ENCODINGS_PATH, "wb") as f:
        f.write(pickle.dumps(data))
    
    print(f"[INFO] Encodings saved to {config.ENCODINGS_PATH}")
    print(f"[INFO] Total known faces encoded: {len(known_encodings)}")

if __name__ == '__main__':
    # This allows running this script directly to build the database
    # Ensure your project structure allows this import or adjust paths if running standalone
    # For example, if running from the root directory: python src/face_encoder.py
    build_known_faces_encodings()
```

```python
# File: main_build_database.py
# Script to trigger the building of the face encodings database.

from src.face_encoder import build_known_faces_encodings

if __name__ == "__main__":
    print("Starting the process to build the face encodings database...")
    build_known_faces_encodings()
    print("Database building process complete.")

```

```python
# File: src/face_recognizer.py
# Module for real-time face recognition logic.

import face_recognition
import pickle
import cv2
import time
from src import config
from src import face_utils # Import utility functions

class RealTimeFaceRecognizer:
    def __init__(self):
        """
        Initializes the face recognizer by loading known face encodings.
        """
        print("[INFO] Loading encodings...")
        try:
            with open(config.ENCODINGS_PATH, "rb") as f:
                self.data = pickle.load(f)
            if not self.data["encodings"]:
                print("[WARNING] Encodings file is empty. Recognition will not work for known faces.")
                print("Please run main_build_database.py to populate encodings.")
        except FileNotFoundError:
            print(f"[ERROR] Encodings file not found at {config.ENCODINGS_PATH}.")
            print("Please run main_build_database.py first.")
            self.data = {"encodings": [], "names": []} # Allow running but with no known faces
        except Exception as e:
            print(f"[ERROR] Could not load encodings file: {e}")
            self.data = {"encodings": [], "names": []}

        self.known_encodings = self.data.get("encodings", [])
        self.known_names = self.data.get("names", [])
        
        print(f"[INFO] {len(self.known_encodings)} known encodings loaded.")


    def start_recognition(self):
        """
        Starts the real-time face recognition using the webcam.
        """
        print("[INFO] Starting video stream...")
        # Use 0 for default webcam. Try other indices if you have multiple cameras.
        vs = cv2.VideoCapture(0) 
        if not vs.isOpened():
            print("[ERROR] Cannot open webcam. Please check camera connection and permissions.")
            return
        
        # Optional: Set frame width (can improve performance)
        vs.set(cv2.CAP_PROP_FRAME_WIDTH, config.FRAME_WIDTH)
        # vs.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) # Example height

        time.sleep(2.0) # Allow camera sensor to warm up

        frame_count = 0
        process_every_n_frames = 2 # Process every Nth frame to save resources

        while True:
            ret, frame = vs.read()
            if not ret or frame is None:
                print("[WARNING] Could not read frame from webcam. Exiting loop.")
                break

            frame_count += 1
            
            # Only process every Nth frame
            if frame_count % process_every_n_frames == 0:
                # Convert the input frame from BGR to RGB then process it
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                # Optional: Resize for faster processing
                # scale_percent = 50 # percent of original size
                # width = int(rgb_frame.shape[1] * scale_percent / 100)
                # height = int(rgb_frame.shape[0] * scale_percent / 100)
                # dim = (width, height)
                # rgb_frame_small = cv2.resize(rgb_frame, dim, interpolation = cv2.INTER_AREA)

                # Detect face locations
                boxes = face_recognition.face_locations(rgb_frame, model=config.DETECTION_MODEL)
                # Compute encodings for faces in the current frame
                current_encodings = face_recognition.face_encodings(rgb_frame, boxes)

                names_on_frame = []
                boxes_on_frame = []
                is_known_on_frame = []

                for encoding, box in zip(current_encodings, boxes):
                    name = "Unknown"
                    is_known = False

                    if self.known_encodings: # Only attempt matching if known encodings exist
                        # Attempt to match each face in the input image to our known encodings
                        matches = face_recognition.compare_faces(self.known_encodings, encoding, tolerance=config.FACE_TOLERANCE)
                        
                        # Check to see if we have found a match
                        if True in matches:
                            # Find the indexes of all matched faces then initialize a
                            # dictionary to count the total number of times each face was matched
                            matched_idxs = [i for (i, b) in enumerate(matches) if b]
                            counts = {}

                            # Loop over the matched indexes and maintain a count for each recognized face
                            for i in matched_idxs:
                                matched_name = self.known_names[i]
                                counts[matched_name] = counts.get(matched_name, 0) + 1
                            
                            # Determine the recognized face with the largest number of votes
                            if counts:
                                name = max(counts, key=counts.get)
                                is_known = True
                    
                    names_on_frame.append(name)
                    boxes_on_frame.append(box) # Store original box coordinates
                    is_known_on_frame.append(is_known)

            # Draw results from the most recently processed frame onto the current frame
            # This ensures smooth video even if processing is slower
            for name, box, is_known_status in zip(names_on_frame, boxes_on_frame, is_known_on_frame):
                # (top, right, bottom, left) = box # these are for the potentially resized frame
                # If you resized, you'd need to scale box coordinates back to original frame size
                face_utils.draw_bounding_box_and_name(frame, name, box, is_known_status)

            # Display the resulting frame
            cv2.imshow("Face Recognition - Press 'q' to quit", frame)
            key = cv2.waitKey(1) & 0xFF

            # If the `q` key was pressed, break from the loop
            if key == ord("q"):
                break
        
        # Cleanup
        print("[INFO] Cleaning up...")
        vs.release()
        cv2.destroyAllWindows()

```

```python
# File: main_realtime_recognition.py
# Main script to run real-time face recognition.

from src.face_recognizer import RealTimeFaceRecognizer

if __name__ == "__main__":
    recognizer = RealTimeFaceRecognizer()
    recognizer.start_recognition()
```

```python
# File: main_image_recognition.py
# Optional: Script to recognize faces in a static image.

import cv2
import face_recognition
import pickle
import os
from src import config
from src import face_utils

def recognize_faces_in_image(image_path):
    """
    Detects and recognizes faces in a single static image.
    """
    if not os.path.exists(image_path):
        print(f"[ERROR] Image not found at {image_path}")
        return

    print("[INFO] Loading encodings...")
    try:
        with open(config.ENCODINGS_PATH, "rb") as f:
            data = pickle.load(f)
        if not data["encodings"]:
            print("[WARNING] Encodings file is empty. Recognition will not work for known faces.")
    except FileNotFoundError:
        print(f"[ERROR] Encodings file not found at {config.ENCODINGS_PATH}. Cannot recognize known faces.")
        data = {"encodings": [], "names": []} # Proceed with 'Unknown' for all
    except Exception as e:
        print(f"[ERROR] Could not load encodings file: {e}")
        data = {"encodings": [], "names": []}

    known_encodings = data.get("encodings", [])
    known_names = data.get("names", [])

    # Load the input image
    image = cv2.imread(image_path)
    if image is None:
        print(f"[ERROR] Could not read image from {image_path}")
        return
        
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    print(f"[INFO] Recognizing faces in {image_path}...")
    boxes = face_recognition.face_locations(rgb_image, model=config.DETECTION_MODEL)
    current_encodings = face_recognition.face_encodings(rgb_image, boxes)

    for encoding, box in zip(current_encodings, boxes):
        name = "Unknown"
        is_known = False

        if known_encodings:
            matches = face_recognition.compare_faces(known_encodings, encoding, tolerance=config.FACE_TOLERANCE)
            if True in matches:
                matched_idxs = [i for (i, b) in enumerate(matches) if b]
                counts = {}
                for i in matched_idxs:
                    matched_name = known_names[i]
                    counts[matched_name] = counts.get(matched_name, 0) + 1
                if counts:
                    name = max(counts, key=counts.get)
                    is_known = True
        
        print(f"- Found {name} at location: {box}")
        face_utils.draw_bounding_box_and_name(image, name, box, is_known)

    # Display the output image
    cv2.imshow(f"Recognized Faces in {os.path.basename(image_path)} - Press any key to close", image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()


if __name__ == "__main__":
    # Example usage:
    # Ensure you have an image in data/unknown_faces or provide a direct path
    test_image_path = os.path.join(config.BASE_DIR, "data", "unknown_faces", "example.jpg") # Change "example.jpg"
    
    # Create a dummy image if it doesn't exist for testing
    if not os.path.exists(os.path.dirname(test_image_path)):
        os.makedirs(os.path.dirname(test_image_path))
    if not os.path.exists(test_image_path):
         # Create a simple dummy image file for testing if one doesn't exist
        print(f"[INFO] Test image {test_image_path} not found. Please place an image there or update the path.")
        # As a placeholder, you might want to skip or point to a known image from your dataset
        # For now, let's try to use an image from known_faces if unknown_faces is empty and no example is provided
        # This is just for demonstration; ideally, the user provides a test image.
        try:
            # Attempt to find any image in known_faces to use as a test
            all_known_images = list(paths.list_images(config.KNOWN_FACES_DIR))
            if all_known_images:
                test_image_path = all_known_images[0]
                print(f"[INFO] Using {test_image_path} as a fallback test image.")
            else:
                print("[INFO] No images found in known_faces either. Cannot run image recognition example without an image.")
                exit()
        except Exception:
            print("[INFO] Could not find a fallback image. Cannot run image recognition example without an image.")
            exit()


    if os.path.exists(test_image_path):
         recognize_faces_in_image(test_image_path)
    else:
        print(f"[INFO] Please provide a valid image path for testing. Current path: {test_image_path}")

